{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bin_sort.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuBJ3cg0ALMP"
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2a8PVG1EVTE"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEbplaMfeQIY"
      },
      "source": [
        "!cp -u /content/drive/MyDrive/merged_Aug9_17_20.zip ./\n",
        "!unzip -n merged_Aug9_17_20.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM-ZXAbTE2bV"
      },
      "source": [
        "!cp -u /content/drive/MyDrive/img_dict.csv ./\n",
        "!cp -u /content/drive/MyDrive/cat_names_dict.csv ./\n",
        "\n",
        "import csv\n",
        "\n",
        "img_cat = dict()\n",
        "with open('img_dict.csv', 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    for row in reader:\n",
        "        img_cat[row[0]] = row[1]\n",
        "\n",
        "cat_names = dict()\n",
        "with open('cat_names_dict.csv', 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    for row in reader:\n",
        "        cat_names[row[0]] = row[1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbqBEON6lBuN"
      },
      "source": [
        "def copy_shoe_imgs(img_cat, cat_names):\n",
        "    \"\"\"Create folder 'shoes' with shoe images only.\n",
        "       \n",
        "       Parameters are two dictionaries\n",
        "       img_cat: key -- img filename, value -- img category\n",
        "       cat_names: key -- category number, value -- category name in Russian\"\"\"\n",
        "\n",
        "    os.mkdir('shoes')\n",
        "    os.mkdir('shoes/M')\n",
        "    os.mkdir('shoes/O')\n",
        "\n",
        "    # categories with shoe images\n",
        "    chosen_cats = [5232, 1542, 5233, 4106, 1532, 579, 2351, 2367, 2133, 2132,\n",
        "                   689, 3338, 692, 954, 3710, 3704, 4418, 2550, 4419, 2129,\n",
        "                   2130, 5232, 2127, 5234]\n",
        "    for cat in chosen_cats:\n",
        "        if str(cat) in cat_names:\n",
        "            print(cat, cat_names[str(cat)])\n",
        "\n",
        "    m_imgs = os.listdir('merged/M')\n",
        "    for img in m_imgs:\n",
        "        if int(img_cat[img]) in chosen_cats:\n",
        "            shutil.copyfile('merged/M/'+img, 'shoes/M/'+img)\n",
        "\n",
        "    o_imgs = os.listdir('merged/O')\n",
        "    for img in o_imgs:\n",
        "        if int(img_cat[img]) in chosen_cats:\n",
        "            shutil.copyfile('merged/O/'+img, 'shoes/O/'+img)\n",
        "\n",
        "    print('shoes Main images', len(os.listdir('shoes/M')),\n",
        "          '\\nshoes Other images', len(os.listdir('shoes/O')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJeaLPDkAlwh"
      },
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install scikit-learn\n",
        "!pip install pytorch-lightning\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch\n",
        "\n",
        "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
        "from pytorch_lightning.metrics.functional import accuracy\n",
        "from torch import nn\n",
        "\n",
        "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from pytorch_lightning.metrics.functional import accuracy\n",
        "import os\n",
        "\n",
        "import ntpath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooPc22XwUmCE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjL1X7FwBAnl"
      },
      "source": [
        "class MyDataModule(LightningDataModule): # rename\n",
        "    def __init__(self, setupdir, tr, va, te, img_cat, seed=0, batch_size=64):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.setupdir = setupdir\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "              transforms.Resize(size=256),\n",
        "              transforms.CenterCrop(size=224),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.te = te\n",
        "        self.tr = tr\n",
        "        self.va = va\n",
        "\n",
        "        self.img_cat = img_cat\n",
        "\n",
        "        self.img_filenames = []\n",
        "\n",
        "        self.seed = seed\n",
        "\n",
        "    #def setup(self):\n",
        "    #    dataset = datasets.ImageFolder(self.setupdir)\n",
        "    #    self.num_classes = len(dataset.classes)\n",
        "    #\n",
        "    #    train_len, val_len = int(0.9 * len(dataset)), int(0.05  * len(dataset))\n",
        "    #    test_len = len(dataset) - train_len - val_len\n",
        "    #    \n",
        "    #    self.train, self.val, self.test = random_split(dataset, [train_len, val_len, test_len])  \n",
        "    #\n",
        "    #    self.train.dataset.transform = self.transform\n",
        "    #    self.val.dataset.transform = self.transform\n",
        "    #    self.test.dataset.transform = self.transform\n",
        "\n",
        "    #def loader(path):\n",
        "        \n",
        "    #    self.img_filenames.append(path)\n",
        "     #   return datasets.folder.default_loader(path)\n",
        "\n",
        "    def setup(self):\n",
        "        torch.manual_seed(self.seed)\n",
        "\n",
        "        dataset = datasets.ImageFolder(self.setupdir)\n",
        "        self.num_classes = len(dataset.classes)\n",
        "\n",
        "        names_dataset = datasets.ImageFolder(self.setupdir,\n",
        "                                             loader=lambda path: path)\n",
        "\n",
        "        self.img_filenames = [ntpath.basename(x[0]) for x in names_dataset]\n",
        "\n",
        "        indices_dict = dict()\n",
        "\n",
        "        for i in range(len(self.img_filenames)):\n",
        "            cat = img_cat[self.img_filenames[i]]\n",
        "            if not cat in indices_dict:\n",
        "                indices_dict[cat] = {'main': [], 'other': []}\n",
        "            is_main = not bool(dataset[i][1])\n",
        "\n",
        "            if is_main:\n",
        "                indices_dict[cat]['main'].append(i)\n",
        "            else:\n",
        "                indices_dict[cat]['other'].append(i)\n",
        "\n",
        "\n",
        "        train_indcs, val_indcs, test_indcs = [], [], []\n",
        "\n",
        "        for cat, indcs in indices_dict.items():\n",
        "            # main imgs\n",
        "            imgs_amount = len(indcs['main'])\n",
        "            if imgs_amount != self.tr + self.va + self.te:\n",
        "                print('amount of main images in any category must be equal\\\n",
        "                       to tr+va+te')\n",
        "                return -1\n",
        "\n",
        "            shuffled = torch.tensor(indcs['main'])[torch.randperm(imgs_amount)]\n",
        "            shuffled = shuffled.tolist()\n",
        "\n",
        "            train_indcs += shuffled[:self.tr]\n",
        "            val_indcs += shuffled[self.tr:self.tr + self.va]\n",
        "            test_indcs += shuffled[-self.te:]\n",
        "\n",
        "            # other imgs\n",
        "            imgs_amount = len(indcs['other'])\n",
        "            if imgs_amount != self.tr + self.va + self.te:\n",
        "                print('amount of other images in any category must be equal\\\n",
        "                       to tr+va+te')\n",
        "                return -1\n",
        "\n",
        "            shuffled = torch.tensor(indcs['other'])[torch.randperm(imgs_amount)]\n",
        "            shuffled = shuffled.tolist()\n",
        "\n",
        "            train_indcs += shuffled[:self.tr]\n",
        "            val_indcs += shuffled[self.tr:self.tr+self.va]\n",
        "            test_indcs += shuffled[-self.te:]\n",
        "\n",
        "        print(train_indcs)\n",
        "\n",
        "        self.train = torch.utils.data.Subset(dataset, train_indcs)\n",
        "        self.val = torch.utils.data.Subset(dataset, val_indcs)\n",
        "        self.test = torch.utils.data.Subset(dataset, test_indcs)\n",
        "\n",
        "        self.train.dataset.transform = self.transform\n",
        "        self.val.dataset.transform = self.transform\n",
        "        self.test.dataset.transform = self.transform        \n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test, batch_size=self.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9QYSWw2V_vn"
      },
      "source": [
        "class MyModel(LightningModule):\n",
        "    def __init__(self, input_shape, num_classes, learning_rate=1e-4, batch_size=64):\n",
        "        super().__init__()\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.save_hyperparameters()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.dim = input_shape\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.feature_extractor = models.resnet34(pretrained=True)\n",
        "        self.feature_extractor.eval() # not necessary\n",
        "\n",
        "        #for param in self.feature_extractor.parameters():\n",
        "            #param.requires_grad = False\n",
        "\n",
        "        n_sizes = self._get_conv_output(input_shape)\n",
        "\n",
        "        # filled after running test_step\n",
        "        # in accordance with the order of the test dataset from datamodule:\n",
        "        # i-th prediction corresponds to the NN result on the i-th element of \n",
        "        # the test dataset\n",
        "        self.predictions = []\n",
        "\n",
        "        self.classifier = torch.nn.Linear(n_sizes, num_classes)\n",
        "\n",
        "    def _get_conv_output(self, shape):\n",
        "        batch_size = 1\n",
        "        input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
        "\n",
        "        output_feat = self._forward_features(input) \n",
        "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
        "        return n_size\n",
        "        \n",
        "    def _forward_features(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        return x\n",
        "    \n",
        "    def forward(self, x):\n",
        "       x = self._forward_features(x) # выдавал бы логиты softmax частью loss'а\n",
        "       x = x.view(x.size(0), -1)\n",
        "       x = F.log_softmax(self.classifier(x), dim=1)\n",
        "\n",
        "       return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x) # уже не логиты\n",
        "        loss = F.nll_loss(logits, y)\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = accuracy(preds, y) # в случае дисбаланса классов мало о чем говорит\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
        "        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)        \n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = accuracy(preds, y)\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = accuracy(preds, y)\n",
        "        \n",
        "        for i in range(len(y)):\n",
        "            self.predictions.append(preds[i])\n",
        "\n",
        "        self.log('test_loss', loss, prog_bar=True)\n",
        "        self.log('test_acc', acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLCdQi_TWPoj"
      },
      "source": [
        "#copy_shoe_imgs(img_cat, cat_names)\n",
        "\n",
        "batch_size = 64\n",
        "dm = MyDataModule(setupdir='merged', tr=15, va=1, te=4,\n",
        "                  img_cat=img_cat, seed=0, batch_size=batch_size)\n",
        "dm.setup()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFpyODcYWSpi"
      },
      "source": [
        "num_classes = dm.num_classes\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dfx3_KHWnSi"
      },
      "source": [
        "model = MyModel((3,224,224), num_classes, batch_size=batch_size, learning_rate=2e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7j_rNDEWrfV"
      },
      "source": [
        "checkpoint = ModelCheckpoint(dirpath='drive/MyDrive/checkpoints', monitor='val_loss', save_top_k=1)\n",
        "\n",
        "trainer = Trainer(max_epochs=4,\n",
        "                  progress_bar_refresh_rate=1,\n",
        "                  gpus = [0],\n",
        "                  callbacks = [checkpoint]) # float point 16 можно использовать\n",
        "# метрика для чекпоинта val loss\n",
        "# early stopping если на трейне уменьшается но на валидации не уменьшается останавливает обучение\n",
        "# чекпоинты сразу на гугл драйв\n",
        "\n",
        "# если время обучения не уменьшилось в два в три раза батч сайз и во столько же раз лернин рейт\n",
        "# best model path аттрибут у чекпоинта через. трайнер тест проверить ее качество \n",
        "# посмотреть где ошибочные изображения\n",
        "\n",
        "trainer.fit(model, dm)\n",
        "\n",
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqFuO12jW72-"
      },
      "source": [
        "# checkpoint_callback = ModelCheckpoint(dirpath='drive/MyDrive/checkpoints')\n",
        "# trainer = Trainer(callbacks=[checkpoint_callback])\n",
        "# trainer.fit(model, dm)\n",
        "# checkpoint_callback.best_model_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-uigq9-ErAr"
      },
      "source": [
        "class ImitateModel():\n",
        "    def __init__(self):\n",
        "        self.predictions = []\n",
        "        with open('/content/drive/MyDrive/raw_predictions.csv', 'r') as csvinput:\n",
        "            reader = csv.reader(csvinput)\n",
        "            for row in reader:\n",
        "                self.predictions.append(torch.tensor(int(row[1])))\n",
        "model = ImitateModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRyIuOEZURjA"
      },
      "source": [
        "print(len(model.predictions))\n",
        "dm.test.dataset[-20][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQNglFJvXPGr"
      },
      "source": [
        "import ntpath\n",
        "\n",
        "# key -- cat,\n",
        "# value -- array:\n",
        "# [right predicted main images, total main images, m img accuracy,\n",
        "# right predicted other images, total other images, o img accuracy,\n",
        "# right predictions in total, prediction in total, total accuracy]\n",
        "prdctns_by_cat = dict()\n",
        "\n",
        "name_ds = dm.img_filenames\n",
        "\n",
        "for i in tqdm(range(len(model.predictions))):\n",
        "    complete_ds_indx = dm.test.indices[i]\n",
        "    img_name = ntpath.basename(name_ds[complete_ds_indx])\n",
        "    cat = img_cat[img_name]\n",
        "\n",
        "    is_main = not bool(dm.test.dataset[complete_ds_indx][1])\n",
        "    \n",
        "    pred = model.predictions[i].item()\n",
        "\n",
        "    pred_correct = (pred == dm.test.dataset[complete_ds_indx][1])\n",
        "    if not cat in prdctns_by_cat:\n",
        "        prdctns_by_cat[cat] = [0, 0, -1.,\n",
        "                               0, 0, -1.,\n",
        "                               0, 0, -1.,]\n",
        "\n",
        "    if is_main:\n",
        "        prdctns_by_cat[cat][1] += 1\n",
        "    else:\n",
        "        prdctns_by_cat[cat][4] += 1 \n",
        "\n",
        "    if pred_correct:\n",
        "        if is_main:\n",
        "            prdctns_by_cat[cat][0] += 1\n",
        "        else:\n",
        "            prdctns_by_cat[cat][3] += 1 \n",
        "\n",
        "for cat, pr_list in prdctns_by_cat.items():\n",
        "    prdctns_by_cat[cat][6] = pr_list[0] + pr_list[3]\n",
        "    prdctns_by_cat[cat][7] = pr_list[1] + pr_list[4]\n",
        "\n",
        "    if pr_list[1] != 0:\n",
        "        prdctns_by_cat[cat][2] = pr_list[0] / pr_list[1]\n",
        "    if pr_list[4] != 0:\n",
        "        prdctns_by_cat[cat][5] = pr_list[3] / pr_list[4]\n",
        "    if pr_list[7] != 0:\n",
        "        prdctns_by_cat[cat][8] = pr_list[6] / pr_list[7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEk7Y8a1UYuy"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('drive/MyDrive/predictions.csv', 'w') as output:\n",
        "    writer = csv.writer(output)\n",
        "\n",
        "    writer.writerow(['cat name', 'base type',\n",
        "                     '# right predictions of main images', '# main images',\n",
        "                     'main images accuracy',\n",
        "                     '# right predictions of other images', '# other images',\n",
        "                     'other images accuracy',\n",
        "                     '# right predictions in total', '# images in total',\n",
        "                     'accuracy in total'])\n",
        "\n",
        "    for cat, pr_list in tqdm(prdctns_by_cat.items()):\n",
        "        row = [cat_names[cat], cat] + pr_list\n",
        "        writer.writerow(row)\n",
        "\n",
        "with open('drive/MyDrive/raw_predictions.csv', 'w') as raw_predictions_csv:\n",
        "    writer = csv.writer(raw_predictions_csv)\n",
        "\n",
        "    for i in tqdm(range(len(model.predictions))):\n",
        "        complete_ds_indx = dm.test.indices[i]\n",
        "        name_ds_element = name_ds[complete_ds_indx]\n",
        "        \n",
        "\n",
        "        img_name = ntpath.basename(name_ds_element)\n",
        "        pred = model.predictions[i].item()\n",
        "\n",
        "        writer.writerow([img_name, pred])\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X14NuU9vFjfT"
      },
      "source": [
        "cats_worst_to_best = sorted(list(prdctns_by_cat.items()), key=lambda x: x[1][8])\n",
        "cats_worst_to_best = [(c[0],c[1][8]) for c in cats_worst_to_best]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpztZ51cEcqd"
      },
      "source": [
        "prdctns_sorted = dict()\n",
        "for i in range(len(model.predictions)):\n",
        "    complete_ds_indx = dm.test.indices[i]\n",
        "    name_ds_element = name_ds[complete_ds_indx]\n",
        "\n",
        "    img_name = ntpath.basename(name_ds_element)\n",
        "    real_label = dm.test.dataset[complete_ds_indx][1]\n",
        "    pred = model.predictions[i].item()\n",
        "\n",
        "    cat = img_cat[img_name]\n",
        "    if not cat in prdctns_sorted:\n",
        "        prdctns_sorted[cat] = {(0,0): [],\n",
        "                               (0,1): [],\n",
        "                               (1,0): [],\n",
        "                               (1,1): []}\n",
        "    prdctns_sorted[cat][(real_label, pred)].append(img_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THxrMhPaGYqB"
      },
      "source": [
        "num_examples = 4\n",
        "examples = dict()\n",
        "\n",
        "for indx in dm.train.indices:\n",
        "    name_ds_element = name_ds[indx]\n",
        "    img_name = ntpath.basename(name_ds_element)\n",
        "\n",
        "    img_label = dm.train.dataset[indx][1]\n",
        "\n",
        "    cat = img_cat[img_name]\n",
        "    if not cat in examples:\n",
        "        examples[cat] = {0: [], 1: []}\n",
        "\n",
        "    if len(examples[cat][img_label]) < num_examples:\n",
        "        examples[cat][img_label].append(img_name)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiKiyGnHPQWo"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import math\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "min8XZePS4HI"
      },
      "source": [
        "def grid_alignment(imgs, grid_height=1, grid_width=None, size=20.):\n",
        "    if not imgs:\n",
        "        return\n",
        "\n",
        "    blank_img = np.zeros([1000,1000,3])\n",
        "    blank_img.fill(1.)\n",
        "\n",
        "    #imgs = [blank_img, blank_img, imgs[0], blank_img]\n",
        "\n",
        "    if not grid_width:\n",
        "        grid_width = math.ceil(len(imgs) / grid_height)\n",
        "\n",
        "\n",
        "    #if grid_width * grid_height < len(imgs):\n",
        "    #    print(\"Make sure grid_width * grid_height is sufficient to\\\n",
        "    #           draw all the images\")\n",
        "    #    return\n",
        "\n",
        "    #grid = ImageGrid(fig, 111,\n",
        "    #                nrows_ncols=(grid_height, grid_width),\n",
        "    #                axes_pad=0.1,\n",
        "    #)\n",
        "\n",
        "\n",
        "    #for ax, im in zip(grid, imgs):\n",
        "    #    ax.imshow(im)\n",
        "    #    ax.axis('off')\n",
        "\n",
        "    _, axarr = plt.subplots(grid_height, grid_width, figsize=(15,15))\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        if grid_height > 1:\n",
        "            axarr[int(i/grid_width),i%grid_width].imshow(img)\n",
        "            axarr[int(i/grid_width),i%grid_width].axis('off')\n",
        "        elif grid_width > 1:\n",
        "            axarr[i].imshow(img)\n",
        "            axarr[i].axis('off')\n",
        "        else:\n",
        "            axarr.imshow(img)\n",
        "            axarr.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBaxKa64BrF8"
      },
      "source": [
        "len(cats_worst_to_best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9tA5n-DUY24"
      },
      "source": [
        "def costyl(img_name):\n",
        "\n",
        "    if img_name[-5] == 'M':\n",
        "        return 'merged/M/'+img_name\n",
        "    else:\n",
        "        return 'merged/O/'+img_name\n",
        "\n",
        "for cat, accuracy in cats_worst_to_best[:20]:\n",
        "    print(cat, cat_names[cat], accuracy)\n",
        "    to_print = {(0,1): \"Main images predicted as Other\",\n",
        "                (1,0): \"Other images predicted as Main\",\n",
        "                (0,0): \"Right predicted Main images\",\n",
        "                (1,1): \"Right predicted Other images\"}\n",
        "    for k in [(0,1), (1,0), (0,0), (1,1)]:\n",
        "        img_names = prdctns_sorted[cat][k]\n",
        "\n",
        "\n",
        "        if img_names:\n",
        "\n",
        "            print(to_print[k])\n",
        "\n",
        "            imgs = [Image.open(costyl(img_name)) for img_name in img_names]\n",
        "            grid_alignment(imgs)\n",
        "\n",
        "            print('. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . '+\n",
        "                '. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ')\n",
        "\n",
        "\n",
        "    print('-------------------------------------------------------------------'+\n",
        "          '-------------------------------------------------------------------')\n",
        "    print('examples')\n",
        "    for k,img_names in examples[cat].items():\n",
        "\n",
        "        if k==0:\n",
        "            print('Main')\n",
        "        else:\n",
        "            print('Other')\n",
        "\n",
        "        imgs = [Image.open(costyl(img_name)) for img_name in img_names]\n",
        "        grid_alignment(imgs)\n",
        "\n",
        "        print('. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . '+\n",
        "            '. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ')\n",
        "\n",
        "\n",
        "    print()\n",
        "    print('==================================================================='+\n",
        "          '===================================================================')\n",
        "    print('==================================================================='+\n",
        "          '===================================================================')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT5wHNOu6315"
      },
      "source": [
        "for cat, accuracy in cats_worst_to_best[-20:]:\n",
        "    print(cat, cat_names[cat], accuracy)\n",
        "    to_print = {(0,1): \"Main images predicted as Other\",\n",
        "                (1,0): \"Other images predicted as Main\",\n",
        "                (0,0): \"Right predicted Main images\",\n",
        "                (1,1): \"Right predicted Other images\"}\n",
        "    for k in [(0,1), (1,0), (0,0), (1,1)]:\n",
        "        img_names = prdctns_sorted[cat][k]\n",
        "\n",
        "\n",
        "        if img_names:\n",
        "\n",
        "            print(to_print[k])\n",
        "\n",
        "            imgs = [Image.open(costyl(img_name)) for img_name in img_names]\n",
        "            grid_alignment(imgs)\n",
        "\n",
        "            print('. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . '+\n",
        "                '. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ')\n",
        "\n",
        "\n",
        "    print('-------------------------------------------------------------------'+\n",
        "          '-------------------------------------------------------------------')\n",
        "    print('examples')\n",
        "    for k,img_names in examples[cat].items():\n",
        "\n",
        "        if k==0:\n",
        "            print('Main')\n",
        "        else:\n",
        "            print('Other')\n",
        "\n",
        "        imgs = [Image.open(costyl(img_name)) for img_name in img_names]\n",
        "        grid_alignment(imgs)\n",
        "\n",
        "        print('. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . '+\n",
        "            '. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ')\n",
        "\n",
        "\n",
        "    print()\n",
        "    print('==================================================================='+\n",
        "          '===================================================================')\n",
        "    print('==================================================================='+\n",
        "          '===================================================================')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGO8ELQNSWAi"
      },
      "source": [
        "from random import randint\n",
        "random_inds = []\n",
        "while len(random_inds) < 20:\n",
        "    next_num = randint(20 + 1, len(cats_worst_to_best) - 20 - 1)\n",
        "    if not next_num in random_inds:\n",
        "        random_inds.append(next_num)\n",
        "\n",
        "random_cats = [cats_worst_to_best[ind] for ind in random_inds]\n",
        "\n",
        "for cat, accuracy in random_cats:\n",
        "    print(cat, cat_names[cat], accuracy)\n",
        "    to_print = {(0,1): \"Main images predicted as Other\",\n",
        "                (1,0): \"Other images predicted as Main\",\n",
        "                (0,0): \"Right predicted Main images\",\n",
        "                (1,1): \"Right predicted Other images\"}\n",
        "    for k in [(0,1), (1,0), (0,0), (1,1)]:\n",
        "        img_names = prdctns_sorted[cat][k]\n",
        "\n",
        "\n",
        "        if img_names:\n",
        "\n",
        "            print(to_print[k])\n",
        "\n",
        "            imgs = [Image.open(costyl(img_name)) for img_name in img_names]\n",
        "            grid_alignment(imgs)\n",
        "\n",
        "            print('. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . '+\n",
        "                '. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ')\n",
        "\n",
        "\n",
        "    print('-------------------------------------------------------------------'+\n",
        "          '-------------------------------------------------------------------')\n",
        "    print('examples')\n",
        "    for k,img_names in examples[cat].items():\n",
        "\n",
        "        if k==0:\n",
        "            print('Main')\n",
        "        else:\n",
        "            print('Other')\n",
        "\n",
        "        imgs = [Image.open(costyl(img_name)) for img_name in img_names]\n",
        "        grid_alignment(imgs)\n",
        "\n",
        "        print('. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . '+\n",
        "            '. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ')\n",
        "\n",
        "\n",
        "    print()\n",
        "    print('==================================================================='+\n",
        "          '===================================================================')\n",
        "    print('==================================================================='+\n",
        "          '===================================================================')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdR-eZMmsSBI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C05V37sssZI6"
      },
      "source": [
        "!"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}